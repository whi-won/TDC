{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "W2-DL_for_TimeSeries-Data",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6eq-RBcQ_Zr"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOjujz601HcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20597a0-214f-4bfc-fc31-f804c6f4d6b9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5oYTQWky4Uf"
      },
      "source": [
        "### 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asEdslR_05O_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4923055e-9269-4a94-a5a1-b9ad28e6f974"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "for val in dataset:\n",
        "   print(val.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9uoa86hy_UK"
      },
      "source": [
        "### 윈도우 씌우기\n",
        "* window size=5 : 한 번에 5개 출력\n",
        "* shift=1 : 윈도우가 한 칸씩 옆으로 움직여!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrv_ghSt1lgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1f49af-9017-4678-d35f-73fac3eb8c15"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1)\n",
        "for window_dataset in dataset:\n",
        "  for val in window_dataset:\n",
        "    print(val.numpy(), end=\" \")\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "6 7 8 9 \n",
            "7 8 9 \n",
            "8 9 \n",
            "9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUBenGEkzDJI"
      },
      "source": [
        "### 데이터 크기 맞추기(?)\n",
        "크기?라고 표현하는게 맞을지.. NLP에서 padding 해서 데이터 크기를 맞췄던 것 처럼, 얘도 크기를 맞춰주는데 얘는 0을 채우는(padding)게 아니라 남는 부분을 자른(drop)다.\n",
        "* `drop_remainder=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLEq6MG-2DN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa304152-66c9-4666-fef8-446afdd81ecc"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "for window_dataset in dataset:\n",
        "  for val in window_dataset:\n",
        "    print(val.numpy(), end=\" \")\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sFJrqY3zlGt"
      },
      "source": [
        "### 넘파이 변환\n",
        "텐서플로우는 데이터가 넘파이인걸 좋아한다!!!!!!!!!! **TensorFlow likes its data to be in numpy format!!!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9CAHlJ2ODe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8244f71-a0ef-4dc1-996a-3434d83924bd"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for window in dataset:\n",
        "  print(window.numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac-LvldDzzcp"
      },
      "source": [
        "### Split features and labels\n",
        "슬라이싱 범위 항상 주의해서 살피기!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DryEZ2Mz2nNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33942d75-e886-4cc6-f6c2-477eef5b6b74"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "for x,y in dataset:\n",
        "  print(x.numpy(), y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3HfEO8L0CNi"
      },
      "source": [
        "### Shuffle\n",
        "This helps us to rearrange the data so as not to accidentally introduce a sequence bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tl-0BOKkEtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca8b9aa-25bc-4ac3-d6bc-f134710b0737"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "for x,y in dataset:\n",
        "  print(x.numpy(), y.numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 3 4 5] [6]\n",
            "[0 1 2 3] [4]\n",
            "[4 5 6 7] [8]\n",
            "[1 2 3 4] [5]\n",
            "[5 6 7 8] [9]\n",
            "[3 4 5 6] [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odhKzQ8y0fU2"
      },
      "source": [
        "### Batching\n",
        "batch size를 2로 설정하면 데이터가 한 번에 두 개의 x와 두 개의 y로 처리된다. By setting a batch size of two, our data gets batched into two x's and two y's at a time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa0PNwxMGapy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8943feb1-13c1-485d-cda8-f8a5539c951e"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "for x,y in dataset:\n",
        "  print(\"x = \", x.numpy())\n",
        "  print(\"y = \", y.numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[1 2 3 4]\n",
            " [4 5 6 7]]\n",
            "y =  [[5]\n",
            " [8]]\n",
            "x =  [[5 6 7 8]\n",
            " [3 4 5 6]]\n",
            "y =  [[9]\n",
            " [7]]\n",
            "x =  [[0 1 2 3]\n",
            " [2 3 4 5]]\n",
            "y =  [[4]\n",
            " [6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sI1oZFS0hHs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}