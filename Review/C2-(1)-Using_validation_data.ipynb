{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "ImageDataGenerator에 validation dir 추가하기, **Augmentation**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from os import getcwd\r\n",
    "import zipfile\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "import random\r\n",
    "from shutil import copyfile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "local_zip = f\"{getcwd()}/../data/cats-and-dogs.zip\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
    "zip_ref.extractall('/tmp')\r\n",
    "zip_ref.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(os.listdir('/tmp/PetImages'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Cat', '.DS_Store', 'Dog']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(os.listdir('/tmp/PetImages/Cat')))\r\n",
    "print(len(os.listdir('/tmp/PetImages/Dog')))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split train and validate directories\n",
    "`SPLIT_SIZE` 비율만큼 train / test data를 나누는 함수 만들기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "try:\r\n",
    "    os.mkdir('/tmp/cats-v-dogs')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\r\n",
    "except OSError:\r\n",
    "    print('Some error occured')\r\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Some error occured\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\r\n",
    "    files=[]\r\n",
    "    print(SOURCE + ' length: {}'.format(len(os.listdir(SOURCE))))\r\n",
    "    \r\n",
    "    # All images should be checked\r\n",
    "    for filename in os.listdir(SOURCE):\r\n",
    "        full_path = SOURCE + filename\r\n",
    "        #print(full_path)\r\n",
    "        \r\n",
    "        if os.path.getsize(full_path)>0:\r\n",
    "            files.append(filename)\r\n",
    "        else:\r\n",
    "            print(filename + \"is zero length!!\")\r\n",
    "    print('valid(not zero length) file length', len(files))\r\n",
    "            \r\n",
    "    # 비율만큼 데이터 크기 정하기\r\n",
    "    training_list_len = int(len(files) * SPLIT_SIZE)\r\n",
    "    testing_list_len = int(len(files) - training_list_len)\r\n",
    "    print(\"split size:\", training_list_len, testing_list_len, \"\\tportion:\", training_list_len/testing_list_len)\r\n",
    "    \r\n",
    "    # Shuffle\r\n",
    "    shuffled_list = random.sample(files, len(files))\r\n",
    "    \r\n",
    "    # Shuffle된 데이터셋으로부터 train and test image 나누기(slicing)\r\n",
    "    training_list = shuffled_list[:training_list_len]\r\n",
    "    testing_list = shuffled_list[-testing_list_len:]\r\n",
    "    print('check shuffled length :', len(training_list), len(testing_list))\r\n",
    "    \r\n",
    "    # 이제 이거를 COPY\r\n",
    "    for filename in training_list:\r\n",
    "        src = SOURCE + filename\r\n",
    "        dst = TRAINING + filename\r\n",
    "        copyfile(src, dst)\r\n",
    "    \r\n",
    "    for filename in testing_list:\r\n",
    "        src = SOURCE + filename\r\n",
    "        dst = TESTING + filename\r\n",
    "        copyfile(src, dst)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\r\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\r\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\r\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\r\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\r\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\r\n",
    "\r\n",
    "split_size = .9\r\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\r\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/tmp/PetImages/Cat/ length: 1500\n",
      "valid(not zero length) file length 1500\n",
      "split size: 1350 150 \tportion: 9.0\n",
      "check shuffled length : 1350 150\n",
      "/tmp/PetImages/Dog/ length: 1500\n",
      "valid(not zero length) file length 1500\n",
      "split size: 1350 150 \tportion: 9.0\n",
      "check shuffled length : 1350 150\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1500\n",
      "1500\n",
      "519\n",
      "511\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "왜 split한 크기는 1350 150인데 copy된 크기는 1498/410 & 1499/403일까... 커널 셧다운 하고 다시 돌리면 맞아질까...?\n",
    "* 뭔가 껐다가 다시 돌릴 때 마다 점점 늘어난다!!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "Augmentaion on ImageDataGenerator\n",
    "* 주의 : ImageDataGenerator를 쓸 경우 모델 fitting도 model.fit이 아니라 `model.fit_generator`임"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "training_dir = '/tmp/cats-v-dogs/training/'\r\n",
    "validation_dir = '/tmp/cats-v-dogs/testing/'\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\r\n",
    "                                  rotation_range=40,\r\n",
    "                                  width_shift_range=0.2,\r\n",
    "                                  height_shift_range=0.2,\r\n",
    "                                  shear_range=0.2,\r\n",
    "                                  zoom_range=0.2,\r\n",
    "                                  horizontal_flip=True,\r\n",
    "                                  fill_mode='nearest')\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "    training_dir,\r\n",
    "    target_size=(150,150),\r\n",
    "    batch_size=10,\r\n",
    "    class_mode='binary'\r\n",
    ")\r\n",
    "\r\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "valid_generator = valid_datagen.flow_from_directory(\r\n",
    "    validation_dir,\r\n",
    "    target_size=(150,150),\r\n",
    "    batch_size=10,\r\n",
    "    class_mode='binary'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2997 images belonging to 2 classes.\n",
      "Found 813 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = tf.keras.models.Sequential([\r\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    \r\n",
    "    tf.keras.layers.Flatten(),\r\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2367616   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,424,065\n",
      "Trainable params: 2,424,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\r\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit_generator(train_generator,\r\n",
    "                             validation_data=valid_generator,\r\n",
    "                             epochs=2,\r\n",
    "                             verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}