{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "W3-Sequence_model-LSTM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFiCyWQ-NC5D"
      },
      "source": [
        "# Multiple Layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y20Lud2ZMBhW"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAU8g7C0MPZE"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW-4Vo4TMUHb"
      },
      "source": [
        "# Get the data\n",
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L11bIR6-PKvs"
      },
      "source": [
        "tokenizer = info.features['text'].encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffvRUI0_McDS"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
        "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbEjcJ-qOKh9"
      },
      "source": [
        "```\n",
        "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        "```\n",
        "* LSTM layer : `tf.keras.layers.LSTM(units=)`\n",
        "  * LSTM에 전달된 파라미터는 units이다. 즉, 예시 코드의 경우 Embedding layer의 output_dim이 64이므로, LSTM 레이어의 유닛으로 64가 똑같이 전달되어야 하는 것.\n",
        "* Bidirectional layer\n",
        "  * LSTM layer를 감싸야 한다(wrap up)\n",
        "  * 이 때 Bidirectional 레이어로 감싸면 cell state를 양방향(both direction)으로 만든다.\n",
        "  * 따라서 `model.summary`를 해 보면 64개 units을 bidirection으로 전달했기 때문에 Output shape은 128로 출력된다!\n",
        "\n",
        "### Multi layer LSTM\n",
        "```\n",
        "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), return_sequences=True),\n",
        "tf.keras.layers.Bidirectioanl(tf.keras.layers.LSTM(32))\n",
        "```\n",
        "멀티레이어의 경우 앞의 레이어에 `return_sequences=True`를 설정해라(default=False). 이 파라미터는 LSTM의 아웃풋이 다음 레이어의 원하는 입력과 일치하게 한다.\n",
        "\n",
        "\n",
        "### LSTM Layer APIs\n",
        "```\n",
        "tf.keras.layers.LSTM(\n",
        "    units, activation='tanh', recurrent_activation='sigmoid',\n",
        "    use_bias=True, kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros', unit_forget_bias=True,\n",
        "    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,\n",
        "    activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
        "    bias_constraint=None, dropout=0.0, recurrent_dropout=0.0,\n",
        "    return_sequences=False, return_state=False, go_backwards=False, stateful=False,\n",
        "    time_major=False, unroll=False, **kwargs\n",
        ")\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo1jjO3vn0jo"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKI5dfPgMioL"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uip7QOVzMoMq"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mlgzaRDMtF6"
      },
      "source": [
        "NUM_EPOCHS = 10\n",
        "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_sX6ilIM515"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFEXtKtqNARB"
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}