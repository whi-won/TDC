{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "W4-Sequence_model-Literature-Realdata",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%204%20-%20Lesson%202%20-%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import numpy as np "
      ],
      "outputs": [],
      "metadata": {
        "id": "BOwsuGQQY9OL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!wget --no-check-certificate \\\r\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\r\n",
        "    -O /tmp/irish-lyrics-eof.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-01-19 16:47:45--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.28.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68970 (67K) [text/plain]\n",
            "Saving to: ‘/tmp/irish-lyrics-eof.txt’\n",
            "\n",
            "\r          /tmp/iris   0%[                    ]       0  --.-KB/s               \r/tmp/irish-lyrics-e 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-01-19 16:47:45 (110 MB/s) - ‘/tmp/irish-lyrics-eof.txt’ saved [68970/68970]\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "pylt5qZYsWPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028f5294-3874-48af-f792-0557dcdaad71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data\n",
        "데이터 구조를 살펴보면 알겠지만 문장과 문장 사이는 엔터로 구분되어 있음."
      ],
      "metadata": {
        "id": "nBJfeMJojGdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "data = open('/tmp/irish-lyrics-eof.txt').read() # 이제 데이터를 하드코딩하는게 아니라 읽어올거임\r\n",
        "\r\n",
        "corpus = data.lower().split(\"\\n\") # 엔터를 기준으로 나눠서 corpus 생성\r\n",
        "\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "total_words = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "print(tokenizer.word_index) # Total number of unique word in this corpus\r\n",
        "print(total_words)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebe370b-c6c4-4dd8-8f02-659d2b11a6bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corpus를 training data로 만들기"
      ],
      "metadata": {
        "id": "RClfxmf3jgNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "input_sequences = []\r\n",
        "for line in corpus:\r\n",
        "  # Then for each line in the corpus, we'll generate a token list using the tokenizers, texts to sequences method.\r\n",
        "  # 이렇게 하면 line of text가 그 줄의 각 단어를 나타내는 token list로 반환됨.\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0] \r\n",
        "\tfor i in range(1, len(token_list)):\r\n",
        "\t\tn_gram_sequence = token_list[:i+1]\r\n",
        "\t\tinput_sequences.append(n_gram_sequence) # 어떤 문장(line)에 대한 input sequence는 line의 token list를 지나오면서 하나씩 추가된다.\r\n",
        "\r\n",
        "# 따라서 어떤 문장(line)의 모든 단어의 token을 갖고 있는 입력 sequence는 맨 마지막 sequence인, input sequences 중 가장 긴 길이를 갖고 있는 sequence일 것이다.\r\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\r\n",
        "\r\n",
        "# pad sequences : 가장 길이가 긴 sequence를 찾았으면 패딩하여 모든 sequence의 길이를 맞춘다. 이 때, 라벨을 쉽게 추출할 수 있도록 *PRE* 패딩한다.\r\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\r\n",
        "\r\n",
        "# 한 문장이 토큰이 하나씩 추가되며 표현되었으므로, 마지막 문자(token)를 제외한 모든 문자를 Input X로 가져가고, 마지막 문자를 Label Y로 가져가게 한다.\r\n",
        " # 슬라이싱 범위 주의\r\n",
        "xs = input_sequences[:,:-1] # [전체, 마지막 하나 빼고 전체]\r\n",
        "labels = input_sequences[:,-1] # [전체, 마지막 하나]\r\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "outputs": [],
      "metadata": {
        "id": "soPGVheskaQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "print(tokenizer.word_index['in'])\r\n",
        "print(tokenizer.word_index['the'])\r\n",
        "print(tokenizer.word_index['town'])\r\n",
        "print(tokenizer.word_index['of'])\r\n",
        "print(tokenizer.word_index['athy'])\r\n",
        "print(tokenizer.word_index['one'])\r\n",
        "print(tokenizer.word_index['jeremy'])\r\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "1\n",
            "71\n",
            "6\n",
            "713\n",
            "39\n",
            "1790\n",
            "1791\n"
          ]
        }
      ],
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba50248-16d6-4582-dd9c-deb1de9895ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "print(xs[6])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n"
          ]
        }
      ],
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb20145-8905-476d-cfad-046b2c92b1cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "print(ys[6])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "metadata": {
        "id": "iY-jwvfgbEF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eafa9e1-b43b-477e-8241-bba75fd763bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "print(xs[5])\r\n",
        "print(ys[5])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0   51   12   96 1217   48\n",
            "    2]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "metadata": {
        "id": "wtzlUMYadhKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d61e01c-6570-421a-fc52-cf54d9bac818"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(tokenizer.word_index)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac24593-b56c-4f0f-bf86-f6f81a07deef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\r\n",
        "model.add(Bidirectional(LSTM(150)))\r\n",
        "model.add(Dense(total_words, activation='softmax'))\r\n",
        "adam = Adam(lr=0.01)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\r\n",
        "history = model.fit(xs, ys, epochs=100, verbose=1)\r\n",
        "#print model.summary()\r\n",
        "print(model)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "377/377 [==============================] - 13s 10ms/step - loss: 6.8250 - accuracy: 0.0635\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 5.7158 - accuracy: 0.1111\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 4.7627 - accuracy: 0.1745\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 3.7858 - accuracy: 0.2534\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 2.8675 - accuracy: 0.3818\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 2.2695 - accuracy: 0.4863\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.7781 - accuracy: 0.5819\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 1.4477 - accuracy: 0.6602\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.2478 - accuracy: 0.7055\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.0951 - accuracy: 0.7358\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9904 - accuracy: 0.7605\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9746 - accuracy: 0.7589\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9731 - accuracy: 0.7581\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.0122 - accuracy: 0.7410\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9813 - accuracy: 0.7461\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.9437 - accuracy: 0.7585\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9317 - accuracy: 0.7572\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8644 - accuracy: 0.7789\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8545 - accuracy: 0.7808\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8186 - accuracy: 0.7871\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8224 - accuracy: 0.7916\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8192 - accuracy: 0.7889\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8004 - accuracy: 0.7895\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8469 - accuracy: 0.7783\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 1.0398 - accuracy: 0.7320\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.0697 - accuracy: 0.7181\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9201 - accuracy: 0.7546\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8346 - accuracy: 0.7748\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7742 - accuracy: 0.7966\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7133 - accuracy: 0.8130\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6960 - accuracy: 0.8169\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6691 - accuracy: 0.8226\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7936 - accuracy: 0.7869\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.9511 - accuracy: 0.7433\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 1.0066 - accuracy: 0.7284\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.9433 - accuracy: 0.7521\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8341 - accuracy: 0.7750\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8119 - accuracy: 0.7831\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7664 - accuracy: 0.7984\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7759 - accuracy: 0.7903\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7663 - accuracy: 0.7927\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7422 - accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7825 - accuracy: 0.7926\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7899 - accuracy: 0.7884\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8607 - accuracy: 0.7679\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8876 - accuracy: 0.7559\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8263 - accuracy: 0.7727\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7691 - accuracy: 0.7949\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7062 - accuracy: 0.8095\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6822 - accuracy: 0.8185\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7091 - accuracy: 0.8069\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.8100\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7468 - accuracy: 0.7967\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8058 - accuracy: 0.7825\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8801 - accuracy: 0.7687\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8392 - accuracy: 0.7725\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8129 - accuracy: 0.7774\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7698 - accuracy: 0.7907\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7488 - accuracy: 0.7980\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7008 - accuracy: 0.8128\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7369 - accuracy: 0.8045\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7853 - accuracy: 0.7895\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8106 - accuracy: 0.7798\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.8112 - accuracy: 0.7822\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7449 - accuracy: 0.7949\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8199 - accuracy: 0.7801\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.8294 - accuracy: 0.7798\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8623 - accuracy: 0.7806\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8153 - accuracy: 0.7811\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7976 - accuracy: 0.7899\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7510 - accuracy: 0.7926\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7362 - accuracy: 0.8051\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8304 - accuracy: 0.7841\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7747 - accuracy: 0.7945\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7797 - accuracy: 0.7931\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7486 - accuracy: 0.7994\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7558 - accuracy: 0.7988\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7417 - accuracy: 0.7991\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7731 - accuracy: 0.7944\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7396 - accuracy: 0.7999\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7550 - accuracy: 0.7995\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7490 - accuracy: 0.7986\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7148 - accuracy: 0.8090\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7547 - accuracy: 0.8025\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7707 - accuracy: 0.7957\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7497 - accuracy: 0.7975\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7897 - accuracy: 0.7868\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7440 - accuracy: 0.7982\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7629 - accuracy: 0.7955\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.8084 - accuracy: 0.7872\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7721 - accuracy: 0.7930\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7757 - accuracy: 0.7964\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7315 - accuracy: 0.8040\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7351 - accuracy: 0.8028\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7247 - accuracy: 0.8044\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7553 - accuracy: 0.7971\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7567 - accuracy: 0.7980\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7558 - accuracy: 0.7952\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 4s 10ms/step - loss: 0.7187 - accuracy: 0.8043\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 0.7099 - accuracy: 0.8066\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f0687b1df28>\n"
          ]
        }
      ],
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7f47a3-1b28-4f48-d1ab-82e1be758a3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def plot_graphs(history, string):\r\n",
        "  plt.plot(history.history[string])\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(string)\r\n",
        "  plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "3YXGelKThoTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "plot_graphs(history, 'accuracy')\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "fd5181ca-beff-4869-dbc6-4950a8f58f3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting a word\n",
        "Let's take a look at how to get a prediction for a word and how to **generate new text** based on those predictions."
      ],
      "metadata": {
        "id": "184p5FKHhfUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "seed_text = \"I've got a bad feeling about this\"\r\n",
        "next_words = 100 # next 100 words를 예측하고 싶다.\r\n",
        "  \r\n",
        "for _ in range(next_words):\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0] # 토크나이저를 이용하여 시퀀스 만들기 this code will tokenizer that for me using the text to sequences method on the tokenizer.\r\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\r\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0) # 모델에 전달하여 다음에 올 확률이 가장 높은 단어의 토큰을 얻을 수 있다. This is will give us the token of the word most likely to be the next one in the sequence\r\n",
        "\toutput_word = \"\"\r\n",
        "\tfor word, index in tokenizer.word_index.items():\r\n",
        "\t\tif index == predicted: # 토큰을 다시 단어로 바꾼다.\r\n",
        "\t\t\toutput_word = word\r\n",
        "\t\t\tbreak\r\n",
        "\tseed_text += \" \" + output_word\r\n",
        "print(seed_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I've got a bad feeling about this that we have taken go to the salley gardens with little snow eyes with lanigans ball or all over each one gone and wines of the day the pipes are calling white friendly rising water of erin across youll see dublin gone and well he had cold love seen a thing the old woman and times more gone by gone by as snow and snow eyes loud and clear as the rose that art sinking funds was night come to find me gone and gone and for me as one dear kissed me darling mother dear dear ye look so\n"
          ]
        }
      ],
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4337a91-f632-4757-c7a5-b1709be5addb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고로 문장이 길어질수록 예측 문장은 횡설수설해진다!\n",
        "\n",
        "이거를 방지(?)하기 위해서는 아주아주 큰 데이터를 넣으면 좀 나아진다."
      ],
      "metadata": {
        "id": "xU2tRs77icLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've got a bad feeling about this that we have taken go to the salley gardens with little snow eyes with lanigans ball or all over each one gone and wines of the day the pipes are calling white friendly rising water of erin across youll see dublin gone and well he had cold love seen a thing the old woman and times more gone by gone by as snow and snow eyes loud and clear as the rose that art sinking funds was night come to find me gone and gone and for me as one dear kissed me darling mother dear dear ye look so\n",
        "\n",
        "오 좀 나아졌나?"
      ],
      "metadata": {
        "id": "wWwsNpzNtvHa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "N5nNSboKifwy"
      }
    }
  ]
}