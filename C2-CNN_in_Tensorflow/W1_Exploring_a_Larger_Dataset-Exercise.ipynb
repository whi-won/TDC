{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "뭐야 이번 문제는 길고 주석이 무지많네"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\r\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\r\n",
    "# ATTENTION: Please use the provided epoch values when training.\r\n",
    "\r\n",
    "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\r\n",
    "# This will require you doing a lot of data preprocessing because\r\n",
    "# the dataset isn't split into training and validation for you\r\n",
    "# This code block has all the required inputs\r\n",
    "import os\r\n",
    "import zipfile\r\n",
    "import random\r\n",
    "import tensorflow as tf\r\n",
    "import shutil\r\n",
    "from tensorflow.keras.optimizers import RMSprop\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "from shutil import copyfile\r\n",
    "from os import getcwd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "# if gpus:\r\n",
    "#     try:\r\n",
    "#         # Currently, memory growth needs to be the same across GPUs\r\n",
    "#         for gpu in gpus:\r\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\r\n",
    "#             logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n",
    "#             print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n",
    "\r\n",
    "#     except RuntimeError as e:\r\n",
    "#         # Memory growth must be set before GPUs have been initialized\r\n",
    "#         print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path_cats_and_dogs = f\"{getcwd()}/../data/cats-and-dogs.zip\"\r\n",
    "#shutil.rmtree('/tmp')\r\n",
    "\r\n",
    "local_zip = path_cats_and_dogs\r\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
    "zip_ref.extractall('/tmp')\r\n",
    "zip_ref.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(len(os.listdir('/tmp/PetImages/Cat/')))\r\n",
    "print(len(os.listdir('/tmp/PetImages/Dog/')))\r\n",
    "\r\n",
    "# Expected Output:\r\n",
    "# 1500\r\n",
    "# 1500"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Use os.mkdir to create your directories\r\n",
    "# You will need a directory for cats-v-dogs, and subdirectories for training\r\n",
    "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\r\n",
    "try:\r\n",
    "    os.mkdir('/tmp/cats-v-dogs')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\r\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\r\n",
    "except OSError:\r\n",
    "    print('error')\r\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "error\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a python function called split_data which takes a SOURCE directory containing the files a TRAINING directory that a portion of the files will be copied to a TESTING directory that a portion of the files will be copie to a SPLIT SIZE to determine the portion\n",
    "\n",
    "The files should also be randomized, so that the training set is a random X% of the files, and the test set is the remaining files\n",
    "\n",
    "SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
    "\n",
    "Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir and 10% of the images will be copied to the TESTING dir\n",
    "Also -- All images should be checked, and if they have a zero file length, they will not be copied over\n",
    "\n",
    "os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
    "\n",
    "os.path.getsize(PATH) gives you the size of the file\n",
    "\n",
    "copyfile(source, destination) copies a file from source to destination\n",
    "\n",
    "random.sample(list, len(list)) shuffles a list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 첫 줄 뭔소린지 잘 모르겠다\n",
    "1.split_data() 함수를 만들어라. argument로는 \n",
    "* SOURCE : Training directory를 포함?\n",
    "* SOURCE 디렉토리는 TESTING 디렉토리로 카피될거래(?)\n",
    "* 예를 들어, *SPILT_SIZE*가 0.9일 경우 이미지의 90%는 TRAINING dir로 카피되고, 나머지 10%는 TESTING dir로 카피될 것.\n",
    "    * 아항 그러면 training dir에 들어갈 이미지를 구하고, testing dir에 들어갈 이미지는 거기서 빼면 되겠다.\n",
    "\n",
    "2.file은 randomized되어야 함. `random.sample(list, len(list))`를 사용할 것.\n",
    "\n",
    "3.맞게 했으면 90%의 이미지가 Training dir,에 카피되고, 나머지 10%는 TEST dir에 카피될 것임.\n",
    "* All  images should be checked\n",
    "    * try-except 아니면 if-else문으로 체크할 것.\n",
    "    \n",
    "디렉토리의 컨텐츠 받아오기 : os.listdir()\n",
    "\n",
    "파일크기 구하기 : os.path.getsize(PATH)\n",
    "\n",
    "src로부터 dst로 파일을 카피하기 : coptyfile(source, destination)\n",
    "\n",
    "리스트 섞기 : random.sample(list, len(list))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "testlist = [2,5,3,1,8,6,7,9]\r\n",
    "pos_test = testlist[:5]\r\n",
    "print(pos_test)\r\n",
    "neg_test = testlist[-5:]\r\n",
    "print(neg_test)\r\n",
    "print(testlist[-5])\r\n",
    "print(len(testlist), testlist[:5], testlist[-3:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2, 5, 3, 1, 8]\n",
      "[1, 8, 6, 7, 9]\n",
      "1\n",
      "8 [2, 5, 3, 1, 8] [6, 7, 9]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Write a python function called split_data which takes\r\n",
    "# a SOURCE directory containing the files\r\n",
    "# a TRAINING directory that a portion of the files will be copied to\r\n",
    "# a TESTING directory that a portion of the files will be copie to\r\n",
    "# a SPLIT SIZE to determine the portion\r\n",
    "# The files should also be randomized, so that the training set is a random\r\n",
    "# X% of the files, and the test set is the remaining files\r\n",
    "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\r\n",
    "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\r\n",
    "# and 10% of the images will be copied to the TESTING dir\r\n",
    "# Also -- All images should be checked, and if they have a zero file length,\r\n",
    "# they will not be copied over\r\n",
    "#\r\n",
    "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\r\n",
    "# os.path.getsize(PATH) gives you the size of the file\r\n",
    "# copyfile(source, destination) copies a file from source to destination\r\n",
    "# random.sample(list, len(list)) shuffles a list\r\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\r\n",
    "    # YOUR CODE STARTS HERE\r\n",
    "    files = []\r\n",
    "    print('original dataset length', len(os.listdir(SOURCE)))\r\n",
    "    \r\n",
    "    # 3. All images should be checked\r\n",
    "    for filename in os.listdir(SOURCE):\r\n",
    "        is_file = SOURCE + filename\r\n",
    "        \r\n",
    "        if os.path.getsize(is_file)>0:\r\n",
    "            # bug 발견....\r\n",
    "            #files.append(is_file)\r\n",
    "            files.append(filename)\r\n",
    "        else:\r\n",
    "            print(filename + \" is zero length!!\")\r\n",
    "        \r\n",
    "    # 1. Train - Test image split\r\n",
    "    # 1.1 Get amount of image using portion\r\n",
    "    training_list_len = int(len(files) * SPLIT_SIZE)\r\n",
    "    testing_list_len = int(len(files) - training_list_len)\r\n",
    "    print('split', training_list_len, testing_list_len)\r\n",
    "    \r\n",
    "    # 2. shuffle하기 -> shuffle한 리스트에서 이미지를 카피할 수 있도록\r\n",
    "    shuffled_dataset = random.sample(files, len(files))\r\n",
    "    \r\n",
    "    # 1.2 Divide training and testing image from shuffeld dataset\r\n",
    "    training_dataset = shuffled_dataset[:training_list_len]\r\n",
    "    testing_dataset = shuffled_dataset[-testing_list_len:]\r\n",
    "    print(\"shuffle\", len(training_dataset), len(testing_dataset))\r\n",
    "    \r\n",
    "    # 1.3 Copy data to TRAINING and TESTING each (using copyfile)\r\n",
    "    for filename in training_dataset:        \r\n",
    "        tmp  = SOURCE + filename        \r\n",
    "        dst = TRAINING + filename\r\n",
    "        copyfile(tmp, dst)\r\n",
    "        \r\n",
    "    for filename in testing_dataset:\r\n",
    "        tmp = SOURCE + filename\r\n",
    "        dst = TESTING + filename\r\n",
    "        copyfile(tmp, dst)\r\n",
    "        \r\n",
    "    # YOUR CODE ENDS HERE\r\n",
    "\r\n",
    "\r\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\r\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\r\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\r\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\r\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\r\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\r\n",
    "\r\n",
    "split_size = .9\r\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\r\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original dataset length 1500\n",
      "split 1350 150\n",
      "shuffle 1350 150\n",
      "original dataset length 1500\n",
      "split 1350 150\n",
      "shuffle 1350 150\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\r\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\r\n",
    "\r\n",
    "# Expected output:\r\n",
    "# 1350\r\n",
    "# 1350\r\n",
    "# 150\r\n",
    "# 150"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1500\n",
      "1500\n",
      "606\n",
      "605\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "get_img_dir = os.listdir('/tmp/cats-v-dogs/training/dogs/')\r\n",
    "get_img_name = get_img_dir[0]\r\n",
    "get_img_name"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dog.749.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "get_img_path = os.path.join(TRAINING_DOGS_DIR, get_img_name)\r\n",
    "get_img_path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/tmp/cats-v-dogs/training/dogs/dog.749.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from PIL import Image\r\n",
    "get_img_size = Image.open(get_img_path)\r\n",
    "get_img_size.size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(400, 425)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\r\n",
    "# USE AT LEAST 3 CONVOLUTION LAYERS\r\n",
    "model = tf.keras.models.Sequential([\r\n",
    "# YOUR CODE HERE\r\n",
    "    # first\r\n",
    "    # 왜 150x150인지는 모르겟지만 뒤에 ImageGenerator로 target_size를 150,150으로 맞출거임...\r\n",
    "    # 그러면 ImageGenerator 코드가 모델링보다 위에 있어야 안 헷갈리지 않나....\r\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    # second\r\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    #third\r\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
    "    \r\n",
    "    # DNN\r\n",
    "    tf.keras.layers.Flatten(),\r\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "])\r\n",
    "\r\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOTE:\n",
    "\n",
    "In the cell below you **MUST** use a batch size of 10 (`batch_size=10`) for the `train_generator` and the `validation_generator`. Using a batch size greater than 10 will exceed memory limits on the Coursera platform."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "TRAINING_DIR = '/tmp/cats-v-dogs/training/'\r\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \r\n",
    "# TRAIN GENERATOR.\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "    TRAINING_DIR,\r\n",
    "    target_size=(150,150),\r\n",
    "    batch_size=10,\r\n",
    "    class_mode='binary'\r\n",
    ")\r\n",
    "\r\n",
    "VALIDATION_DIR = '/tmp/cats-v-dogs/testing/'\r\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \r\n",
    "# VALIDATION GENERATOR.\r\n",
    "validation_generator = validation_datagen.flow_from_directory(\r\n",
    "    VALIDATION_DIR,\r\n",
    "    target_size=(150,150),\r\n",
    "    batch_size=10,\r\n",
    "    class_mode='binary'\r\n",
    ")\r\n",
    "\r\n",
    "# Expected Output:\r\n",
    "# Found 2700 images belonging to 2 classes.\r\n",
    "# Found 300 images belonging to 2 classes."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 1211 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit_generator(train_generator,\r\n",
    "                              epochs=2,\r\n",
    "                              verbose=1,\r\n",
    "                              validation_data=validation_generator)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# PLOT LOSS AND ACCURACY\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import matplotlib.image  as mpimg\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#-----------------------------------------------------------\r\n",
    "# Retrieve a list of list results on training and test data\r\n",
    "# sets for each training epoch\r\n",
    "#-----------------------------------------------------------\r\n",
    "acc=history.history['acc']\r\n",
    "val_acc=history.history['val_acc']\r\n",
    "loss=history.history['loss']\r\n",
    "val_loss=history.history['val_loss']\r\n",
    "\r\n",
    "epochs=range(len(acc)) # Get number of epochs\r\n",
    "\r\n",
    "#------------------------------------------------\r\n",
    "# Plot training and validation accuracy per epoch\r\n",
    "#------------------------------------------------\r\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\r\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\r\n",
    "plt.title('Training and validation accuracy')\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "#------------------------------------------------\r\n",
    "# Plot training and validation loss per epoch\r\n",
    "#------------------------------------------------\r\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\r\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\r\n",
    "\r\n",
    "\r\n",
    "plt.title('Training and validation loss')\r\n",
    "\r\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean up\n",
    "메모리 리소스 해제"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, signal\r\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}