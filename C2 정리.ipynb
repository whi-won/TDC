{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"TDC 실습 정리","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNa0OSkcNdW9lLPgj60t/86"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"source":["#!pip install tensorflow==2.5.0"],"outputs":[],"metadata":{"id":"IoxzwrMfBqGJ"}},{"cell_type":"code","execution_count":1,"source":["import tensorflow as tf\r\n","import numpy as np\r\n","from tensorflow import keras\r\n","from tensorflow.keras.optimizers import RMSprop"],"outputs":[],"metadata":{"id":"PUNO2E6SeURH","executionInfo":{"status":"ok","timestamp":1631682336532,"user_tz":-540,"elapsed":2626,"user":{"displayName":"whiwon Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09094003252511662507"}}}},{"cell_type":"code","execution_count":null,"source":["class myCallback(tf.keras.callbacks.Callback):\r\n","  def on_epoch_end(self, epoch, logs={}):\r\n","    if(logs.get('accuracy') is not None and logs.get('accuracy') >= 0.8): # Experiment with changing this value\r\n","      print(\"\\nReached 80% accuracy so cancelling training!\")\r\n","      self.model.stop_training = True"],"outputs":[],"metadata":{"id":"o_RjJIKhAh1w"}},{"cell_type":"markdown","source":["## **MISSION: 데이터 전처리**\r\n","이 데이터로 모델을 학습시키기 위해선 각종 전처리가 필요합니다.\r\n","\r\n","TFDS 패키지를 이용한 것이 아니므로 ImageDataGenerator를 이용하여 전처리를 진행할 것입니다.\r\n","\r\n","<br>\r\n","\r\n","0-255 사이의 pixel 값을 0-1 사이의 float 값으로 Normalize를 실시하고,\r\n","Train / Validation 의 비율을 8:2로 설정하겠습니다.\r\n","\r\n","<br>\r\n","\r\n","설정한 데이터를 flow_from_directory를 이용하여 Resize, batch_size, class_mode를 지정하겠습니다.\r\n","데이터의 크기는 150x150 으로 Resize를 실시할 것이며,\r\n","batch_size는 20,\r\n","class_mode는 categorical로 지정하겠습니다.\r\n","여기서 categorical로 지정하면 label 정보가 one-hot encoding으로 설정됩니다.\r\n","<br>\r\n","\r\n","ImageDataGenerator에 Augmentation을 적용 -> 속도가 느려질순 있음\r\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["TRAINING_DIR = \"tmp/rps/\"\r\n","\r\n","training_datagen = ImageDataGenerator(\r\n","  rescale=1. / 255,\r\n","  validation_split=0.2,\r\n","  rotation_range=5,\r\n","  width_shift_range=0.2,\r\n","  height_shift_range=0.2,\r\n","  horizontal_flip=True\r\n",")\r\n","\r\n","# 카테고리로 설정해서 진행할 경우는 이렇게\r\n","# 애초에 dir가 나누어져 있으면 각각 디렉토리 따로 설정한다. validatio_split 없이\r\n","train_generator = training_datagen.flow_from_directory(\r\n","      TRAINING_DIR, \r\n","      target_size=(150, 150), \r\n","      batch_size=20, \r\n","      class_mode='categorical', \r\n","      subset='training', #validation 비율 따라서 나눠짐\r\n","    )\r\n","\r\n","validation_generator = training_datagen.flow_from_directory(\r\n","      TRAINING_DIR, \r\n","      target_size=(150, 150), \r\n","      batch_size=20, \r\n","      class_mode='categorical',\r\n","      subset='validation',\r\n","      )\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# 이렇게 데이터를 데이터를 전처리하는 경우도 있었음\r\n","def preprocess(features):\r\n","  \r\n","    img = features['image']\r\n","    label = features['label']\r\n","    img = tf.image.resize(img, [224, 224])\r\n","    img = tf.cast(img, tf.float32)\r\n","    img = img / 255.0\r\n","\r\n","    return img, label\r\n","\r\n","train_dataset = dataset.map(preprocess).batch(32)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## **MISSION: 네트워크 학습**\r\n","## **예시 답안**\r\n","\r\n","아까 flow_from_directory에서 Categorical로 class_mode를 지정하였으니 loss 함수로는 Catogoricalentropy를 사용합니다.\r\n","혹시나 sparse로 지정하였다면, SparseCategoricalCrossentropy를 사용하여 compile 합니다.\r\n","Optimizer의 경우에는 SGD, Adam, RMSprop, ... 등 아무거나 선택하셔도 무방합니다.\r\n","\r\n","<br>\r\n","\r\n","학습은 15 epoch을 실시하였고, 더 줄이거나 늘려도 문제 없습니다.\r\n","validation accuracy가 80% 이상 나오도록 위의 네트워크 구조 및 학습 epoch 수를 변경하시면 좋습니다."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = tf.keras.models.Sequential([\r\n","        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\r\n","        tf.keras.layers.MaxPooling2D(2, 2),\r\n","        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\r\n","        tf.keras.layers.MaxPooling2D(2, 2),\r\n","        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n","        tf.keras.layers.MaxPooling2D(2, 2),\r\n","        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\r\n","        tf.keras.layers.MaxPooling2D(2, 2),\r\n","        tf.keras.layers.Flatten(),\r\n","        tf.keras.layers.Dense(256, activation='relu'),\r\n","        tf.keras.layers.Dense(256, activation='relu'),\r\n","        tf.keras.layers.Dense(3, activation='softmax') #분류를 몇개로 하나에 따라서 값 바뀜\r\n","    ])\r\n","\r\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(),\r\n","              loss='categorical_crossentropy',\r\n","              metrics=['accuracy'])\r\n","\r\n","# model.compile(optimizer=RMSprop(lr=0.001),\r\n","#               loss='binary_crossentropy',\r\n","#               metrics = ['accuracy'])\r\n","\r\n","model.fit(train_generator, epochs=15, validation_data=validation_generator)\r\n","model.save(\"rps.h5\")"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## 위에는 3개 분류라서 categorical\r\n","## binary 예제는 아래"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!wget --no-check-certificate \\\r\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\r\n","    -O /tmp/cats_and_dogs_filtered.zip\r\n","  \r\n","import os\r\n","import zipfile\r\n","import tensorflow as tf\r\n","from tensorflow.keras.optimizers import RMSprop\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","local_zip = '/tmp/cats_and_dogs_filtered.zip'\r\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n","zip_ref.extractall('/tmp')\r\n","zip_ref.close()\r\n","\r\n","base_dir = '/tmp/cats_and_dogs_filtered'\r\n","train_dir = os.path.join(base_dir, 'train')\r\n","validation_dir = os.path.join(base_dir, 'validation')\r\n","\r\n","train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\r\n","train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\r\n","validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\r\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\r\n","\r\n","#데이터 확인\r\n","train_cat_fnames = os.listdir( train_cats_dir )\r\n","train_dog_fnames = os.listdir( train_dogs_dir )\r\n","print(train_cat_fnames[:10])\r\n","print(train_dog_fnames[:10])\r\n","print('total training cat images :', len(os.listdir(train_cats_dir ) ))\r\n","print('total training dog images :', len(os.listdir(train_dogs_dir ) ))\r\n","print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\r\n","print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\r\n","\r\n","model = tf.keras.models.Sequential([\r\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\r\n","    tf.keras.layers.MaxPooling2D(2, 2),\r\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Flatten(),\r\n","    tf.keras.layers.Dense(512, activation='relu'),\r\n","    tf.keras.layers.Dense(1, activation='sigmoid')\r\n","])\r\n","\r\n","model.compile(loss='binary_crossentropy',\r\n","              optimizer=RMSprop(lr=1e-4),\r\n","              metrics=['accuracy'])\r\n","\r\n","# Train용 에다가만 augmentation 부여!\r\n","train_datagen = ImageDataGenerator(\r\n","      rescale=1./255,\r\n","      rotation_range=40,\r\n","      width_shift_range=0.2,\r\n","      height_shift_range=0.2,\r\n","      shear_range=0.2,\r\n","      zoom_range=0.2,\r\n","      horizontal_flip=True,\r\n","      fill_mode='nearest')\r\n","\r\n","test_datagen = ImageDataGenerator(rescale=1./255)\r\n","\r\n","# Flow training images in batches of 20 using train_datagen generator\r\n","train_generator = train_datagen.flow_from_directory(\r\n","        train_dir,  # This is the source directory for training images\r\n","        target_size=(150, 150),  # All images will be resized to 150x150\r\n","        batch_size=20,\r\n","        # Since we use binary_crossentropy loss, we need binary labels\r\n","        class_mode='binary')\r\n","\r\n","# Flow validation images in batches of 20 using test_datagen generator\r\n","validation_generator = test_datagen.flow_from_directory(\r\n","        validation_dir,\r\n","        target_size=(150, 150),\r\n","        batch_size=20,\r\n","        class_mode='binary')\r\n","\r\n","history = model.fit(\r\n","      train_generator,\r\n","      steps_per_epoch=100,  # 2000 images = batch_size * steps\r\n","      epochs=100,\r\n","      validation_data=validation_generator,\r\n","      validation_steps=50,  # 1000 images = batch_size * steps\r\n","      verbose=2)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 데이터 학습정도 그래프로 확인"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#-----------------------------------------------------------\r\n","# Retrieve a list of list results on training and test data\r\n","# sets for each training epoch\r\n","#-----------------------------------------------------------\r\n","acc      = history.history[     'accuracy' ]\r\n","val_acc  = history.history[ 'val_accuracy' ]\r\n","loss     = history.history[    'loss' ]\r\n","val_loss = history.history['val_loss' ]\r\n","\r\n","epochs   = range(len(acc)) # Get number of epochs\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation accuracy per epoch\r\n","#------------------------------------------------\r\n","plt.plot  ( epochs,     acc )\r\n","plt.plot  ( epochs, val_acc )\r\n","plt.title ('Training and validation accuracy')\r\n","plt.figure()\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation loss per epoch\r\n","#------------------------------------------------\r\n","plt.plot  ( epochs,     loss )\r\n","plt.plot  ( epochs, val_loss )\r\n","plt.title ('Training and validation loss'   )"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 만약 이미지 확인이 필요할 경우 아래 코드로 확인"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# PLOT LOSS AND ACCURACY\r\n","%matplotlib inline\r\n","\r\n","import matplotlib.image  as mpimg\r\n","import matplotlib.pyplot as plt\r\n","\r\n","#-----------------------------------------------------------\r\n","# Retrieve a list of list results on training and test data\r\n","# sets for each training epoch\r\n","#-----------------------------------------------------------\r\n","acc=history.history['acc']\r\n","val_acc=history.history['val_acc']\r\n","loss=history.history['loss']\r\n","val_loss=history.history['val_loss']\r\n","\r\n","epochs=range(len(acc)) # Get number of epochs\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation accuracy per epoch\r\n","#------------------------------------------------\r\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\r\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\r\n","plt.title('Training and validation accuracy')\r\n","plt.figure()\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation loss per epoch\r\n","#------------------------------------------------\r\n","plt.plot(epochs, loss, 'r', \"Training Loss\")\r\n","plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\r\n","\r\n","\r\n","plt.title('Training and validation loss')\r\n","\r\n","# Desired output. Charts with training and validation metrics. No crash :)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### 혹시나 이미지 split이 직접 필요한 경우"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import os\r\n","import zipfile\r\n","import random\r\n","import tensorflow as tf\r\n","import shutil\r\n","from tensorflow.keras.optimizers import RMSprop\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from shutil import copyfile\r\n","from os import getcwd\r\n","# Use os.mkdir to create your directories\r\n","# You will need a directory for cats-v-dogs, and subdirectories for training\r\n","# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\r\n","try:\r\n","    os.mkdir('/tmp/cats-v-dogs')\r\n","    os.mkdir('/tmp/cats-v-dogs/training')\r\n","    os.mkdir('/tmp/cats-v-dogs/testing')\r\n","    os.mkdir('/tmp/cats-v-dogs/training/cats')\r\n","    os.mkdir('/tmp/cats-v-dogs/training/dogs')\r\n","    os.mkdir('/tmp/cats-v-dogs/testing/cats')\r\n","    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\r\n","except OSError:\r\n","    print('error')\r\n","    pass\r\n","# Write a python function called split_data which takes\r\n","# a SOURCE directory containing the files\r\n","# a TRAINING directory that a portion of the files will be copied to\r\n","# a TESTING directory that a portion of the files will be copie to\r\n","# a SPLIT SIZE to determine the portion\r\n","# The files should also be randomized, so that the training set is a random\r\n","# X% of the files, and the test set is the remaining files\r\n","# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\r\n","# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\r\n","# and 10% of the images will be copied to the TESTING dir\r\n","# Also -- All images should be checked, and if they have a zero file length,\r\n","# they will not be copied over\r\n","#\r\n","# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\r\n","# os.path.getsize(PATH) gives you the size of the file\r\n","# copyfile(source, destination) copies a file from source to destination\r\n","# random.sample(list, len(list)) shuffles a list\r\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\r\n","    # YOUR CODE STARTS HERE\r\n","    files = []\r\n","    print('original dataset length', len(os.listdir(SOURCE)))\r\n","    \r\n","    # 3. All images should be checked\r\n","    for filename in os.listdir(SOURCE):\r\n","        is_file = SOURCE + filename\r\n","        \r\n","        if os.path.getsize(is_file)>0:\r\n","            # bug 발견....\r\n","            #files.append(is_file)\r\n","            files.append(filename)\r\n","        else:\r\n","            print(filename + \" is zero length!!\")\r\n","        \r\n","    # 1. Train - Test image split\r\n","    # 1.1 Get amount of image using portion\r\n","    training_list_len = int(len(files) * SPLIT_SIZE)\r\n","    testing_list_len = int(len(files) - training_list_len)\r\n","    print('split', training_list_len, testing_list_len)\r\n","    \r\n","    # 2. shuffle하기 -> shuffle한 리스트에서 이미지를 카피할 수 있도록\r\n","    shuffled_dataset = random.sample(files, len(files))\r\n","    \r\n","    # 1.2 Divide training and testing image from shuffeld dataset\r\n","    training_dataset = shuffled_dataset[:training_list_len]\r\n","    testing_dataset = shuffled_dataset[-testing_list_len:]\r\n","    print(\"shuffle\", len(training_dataset), len(testing_dataset))\r\n","    \r\n","    # 1.3 Copy data to TRAINING and TESTING each (using copyfile)\r\n","    for filename in training_dataset:        \r\n","        tmp  = SOURCE + filename        \r\n","        dst = TRAINING + filename\r\n","        copyfile(tmp, dst)\r\n","        \r\n","    for filename in testing_dataset:\r\n","        tmp = SOURCE + filename\r\n","        dst = TESTING + filename\r\n","        copyfile(tmp, dst)\r\n","        \r\n","    # YOUR CODE ENDS HERE\r\n","\r\n","\r\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\r\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\r\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\r\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\r\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\r\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\r\n","\r\n","split_size = .9\r\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\r\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"],"outputs":[],"metadata":{}}]}